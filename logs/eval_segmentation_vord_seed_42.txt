Traceback (most recent call last):
  File "/home/dexter/VisionReasoner/evaluation/evaluation_segmentation.py", line 17, in <module>
    from vision_reasoner.models.vision_reasoner_model import VisionReasonerModel
  File "/home/dexter/VisionReasoner/vision_reasoner/models/vision_reasoner_model.py", line 6, in <module>
    from transformers import (
  File "<frozen importlib._bootstrap>", line 1412, in _handle_fromlist
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/utils/import_utils.py", line 2317, in __getattr__
    module = self._get_module(self._class_to_module[name])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/utils/import_utils.py", line 2345, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/models/__init__.py", line 396, in <module>
    sys.modules[__name__] = _LazyModule(__name__, _file, define_import_structure(_file), module_spec=__spec__)
                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/utils/import_utils.py", line 2867, in define_import_structure
    import_structure = create_import_structure_from_path(module_path)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/utils/import_utils.py", line 2580, in create_import_structure_from_path
    import_structure[f] = create_import_structure_from_path(os.path.join(module_path, f))
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/utils/import_utils.py", line 2703, in create_import_structure_from_path
    for _all_object in fetch__all__(file_content):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/utils/import_utils.py", line 2473, in fetch__all__
    def fetch__all__(file_content) -> list[str]:
    
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/dexter/VisionReasoner/evaluation/evaluation_segmentation.py", line 13, in <module>
    from vcd_sample import evolve_guidance_sampling
  File "/home/dexter/VisionReasoner/evaluation/vcd_sample.py", line 14, in <module>
    from transformers.generation.logits_process import (
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/__init__.py", line 958, in <module>
    import_structure = define_import_structure(Path(__file__).parent / "models", prefix="models")
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/utils/import_utils.py", line 2868, in define_import_structure
    spread_dict = spread_import_structure(import_structure)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/utils/import_utils.py", line 2830, in spread_import_structure
    ordered_import_structure = propagate_frozenset(ordered_import_structure)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/utils/import_utils.py", line 2809, in propagate_frozenset
    frozenset_first_import_structure[_key] = propagate_frozenset(_value)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/utils/import_utils.py", line 2771, in propagate_frozenset
    elif any(isinstance(v, frozenset) for v in _value):
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/utils/import_utils.py", line 2771, in <genexpr>
    elif any(isinstance(v, frozenset) for v in _value):
             ^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/dexter/VisionReasoner/evaluation/evaluation_segmentation.py", line 17, in <module>
    from vision_reasoner.models.vision_reasoner_model import VisionReasonerModel
  File "/home/dexter/VisionReasoner/vision_reasoner/models/vision_reasoner_model.py", line 6, in <module>
    from transformers import (
  File "<frozen importlib._bootstrap>", line 1412, in _handle_fromlist
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/utils/import_utils.py", line 2317, in __getattr__
    module = self._get_module(self._class_to_module[name])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/utils/import_utils.py", line 2345, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 34, in <module>
    from ...activations import ACT2FN
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/activations.py", line 22, in <module>
    from .integrations.hub_kernels import use_kernel_forward_from_hub
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/integrations/hub_kernels.py", line 19, in <module>
    from .flash_attention import flash_attention_forward
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/integrations/flash_attention.py", line 11, in <module>
    _use_top_left_mask = flash_attn_supports_top_left_mask()
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/modeling_flash_attention_utils.py", line 38, in flash_attn_supports_top_left_mask
    if is_flash_attn_2_available():
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/utils/import_utils.py", line 1199, in is_flash_attn_2_available
    if not (torch.cuda.is_available() or is_torch_mlu_available()):
            ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/torch/cuda/__init__.py", line 182, in is_available
    return torch._C._cuda_getDeviceCount() > 0
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
evaluation/eval_segmentation.sh: line 51: kill: (-2433603) - No such process
evaluation/eval_segmentation.sh: line 51: kill: (-2433603) - No such process
Traceback (most recent call last):
  File "/home/dexter/VisionReasoner/evaluation/evaluation_segmentation.py", line 17, in <module>
    from vision_reasoner.models.vision_reasoner_model import VisionReasonerModel
  File "/home/dexter/VisionReasoner/vision_reasoner/models/vision_reasoner_model.py", line 6, in <module>
    from transformers import (
  File "<frozen importlib._bootstrap>", line 1412, in _handle_fromlist
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/utils/import_utils.py", line 2317, in __getattr__
    module = self._get_module(self._class_to_module[name])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/utils/import_utils.py", line 2345, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 34, in <module>
    from ...activations import ACT2FN
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/activations.py", line 22, in <module>
    from .integrations.hub_kernels import use_kernel_forward_from_hub
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/integrations/hub_kernels.py", line 19, in <module>
    from .flash_attention import flash_attention_forward
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/integrations/flash_attention.py", line 11, in <module>
    _use_top_left_mask = flash_attn_supports_top_left_mask()
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/modeling_flash_attention_utils.py", line 38, in flash_attn_supports_top_left_mask
    if is_flash_attn_2_available():
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/utils/import_utils.py", line 1199, in is_flash_attn_2_available
    if not (torch.cuda.is_available() or is_torch_mlu_available()):
            ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/torch/cuda/__init__.py", line 182, in is_available
    return torch._C._cuda_getDeviceCount() > 0
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/dexter/VisionReasoner/evaluation/evaluation_segmentation.py", line 17, in <module>
    from vision_reasoner.models.vision_reasoner_model import VisionReasonerModel
  File "/home/dexter/VisionReasoner/vision_reasoner/models/vision_reasoner_model.py", line 6, in <module>
    from transformers import (
  File "<frozen importlib._bootstrap>", line 1412, in _handle_fromlist
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/utils/import_utils.py", line 2317, in __getattr__
    module = self._get_module(self._class_to_module[name])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/utils/import_utils.py", line 2345, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 34, in <module>
    from ...activations import ACT2FN
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/activations.py", line 22, in <module>
    from .integrations.hub_kernels import use_kernel_forward_from_hub
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/integrations/hub_kernels.py", line 19, in <module>
    from .flash_attention import flash_attention_forward
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/integrations/flash_attention.py", line 11, in <module>
    _use_top_left_mask = flash_attn_supports_top_left_mask()
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/modeling_flash_attention_utils.py", line 38, in flash_attn_supports_top_left_mask
    if is_flash_attn_2_available():
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/utils/import_utils.py", line 1199, in is_flash_attn_2_available
    if not (torch.cuda.is_available() or is_torch_mlu_available()):
            ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/torch/cuda/__init__.py", line 182, in is_available
    return torch._C._cuda_getDeviceCount() > 0
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/dexter/VisionReasoner/evaluation/evaluation_segmentation.py", line 17, in <module>
    from vision_reasoner.models.vision_reasoner_model import VisionReasonerModel
  File "/home/dexter/VisionReasoner/vision_reasoner/models/vision_reasoner_model.py", line 6, in <module>
    from transformers import (
  File "<frozen importlib._bootstrap>", line 1412, in _handle_fromlist
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/utils/import_utils.py", line 2317, in __getattr__
    module = self._get_module(self._class_to_module[name])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/utils/import_utils.py", line 2345, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 34, in <module>
    from ...activations import ACT2FN
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/activations.py", line 22, in <module>
    from .integrations.hub_kernels import use_kernel_forward_from_hub
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/integrations/hub_kernels.py", line 19, in <module>
    from .flash_attention import flash_attention_forward
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/integrations/flash_attention.py", line 11, in <module>
    _use_top_left_mask = flash_attn_supports_top_left_mask()
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/modeling_flash_attention_utils.py", line 38, in flash_attn_supports_top_left_mask
    if is_flash_attn_2_available():
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/utils/import_utils.py", line 1199, in is_flash_attn_2_available
    if not (torch.cuda.is_available() or is_torch_mlu_available()):
            ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/torch/cuda/__init__.py", line 182, in is_available
    return torch._C._cuda_getDeviceCount() > 0
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/dexter/VisionReasoner/evaluation/evaluation_segmentation.py", line 17, in <module>
    from vision_reasoner.models.vision_reasoner_model import VisionReasonerModel
  File "/home/dexter/VisionReasoner/vision_reasoner/models/vision_reasoner_model.py", line 6, in <module>
    from transformers import (
  File "<frozen importlib._bootstrap>", line 1412, in _handle_fromlist
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/utils/import_utils.py", line 2317, in __getattr__
    module = self._get_module(self._class_to_module[name])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/utils/import_utils.py", line 2345, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 34, in <module>
    from ...activations import ACT2FN
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/activations.py", line 22, in <module>
    from .integrations.hub_kernels import use_kernel_forward_from_hub
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/integrations/hub_kernels.py", line 19, in <module>
    from .flash_attention import flash_attention_forward
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/integrations/flash_attention.py", line 11, in <module>
    _use_top_left_mask = flash_attn_supports_top_left_mask()
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/modeling_flash_attention_utils.py", line 38, in flash_attn_supports_top_left_mask
    if is_flash_attn_2_available():
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/utils/import_utils.py", line 1199, in is_flash_attn_2_available
    if not (torch.cuda.is_available() or is_torch_mlu_available()):
            ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/torch/cuda/__init__.py", line 182, in is_available
    return torch._C._cuda_getDeviceCount() > 0
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/dexter/VisionReasoner/evaluation/evaluation_segmentation.py", line 17, in <module>
    from vision_reasoner.models.vision_reasoner_model import VisionReasonerModel
  File "/home/dexter/VisionReasoner/vision_reasoner/models/vision_reasoner_model.py", line 6, in <module>
    from transformers import (
  File "<frozen importlib._bootstrap>", line 1412, in _handle_fromlist
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/utils/import_utils.py", line 2317, in __getattr__
    module = self._get_module(self._class_to_module[name])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/utils/import_utils.py", line 2345, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 34, in <module>
    from ...activations import ACT2FN
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/activations.py", line 22, in <module>
    from .integrations.hub_kernels import use_kernel_forward_from_hub
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/integrations/hub_kernels.py", line 19, in <module>
    from .flash_attention import flash_attention_forward
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/integrations/flash_attention.py", line 11, in <module>
    _use_top_left_mask = flash_attn_supports_top_left_mask()
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/modeling_flash_attention_utils.py", line 38, in flash_attn_supports_top_left_mask
    if is_flash_attn_2_available():
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/transformers/utils/import_utils.py", line 1199, in is_flash_attn_2_available
    if not (torch.cuda.is_available() or is_torch_mlu_available()):
            ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dexter/anaconda3/envs/VisionReasoner/lib/python3.12/site-packages/torch/cuda/__init__.py", line 182, in is_available
    return torch._C._cuda_getDeviceCount() > 0
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
evaluation/eval_segmentation.sh: line 51: kill: (-2433603) - No such process
evaluation/eval_segmentation.sh: line 51: kill: (-2433603) - No such process
evaluation/eval_segmentation.sh: line 51: kill: (-2433603) - No such process
evaluation/eval_segmentation.sh: line 51: kill: (-2433603) - No such process
evaluation/eval_segmentation.sh: line 51: kill: (-2433603) - No such process
evaluation/eval_segmentation.sh: line 51: kill: (-2433603) - No such process
